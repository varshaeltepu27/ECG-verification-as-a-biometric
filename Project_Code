import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, ReLU, Add, Dense, GlobalAveragePooling1D
from tensorflow.keras.preprocessing.sequence import pad_sequences
import scipy.signal
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Load the training and testing data
train_df = pd.read_excel('/content/17PersonsTrainData.xlsx')  # Provide your training data file path
test_df = pd.read_excel('/content/17PersonsTestData.xlsx')    # Provide your testing data file path

# Extract names and ECG data for training
train_individuals = train_df.iloc[:, 0].values  # Names of individuals
train_ecg_data = train_df.iloc[:, 1:].values  # ECG data starts from the second column

# Extract names and ECG data for testing
test_individuals = test_df.iloc[:, 0].values  # Names of individuals
test_ecg_data = test_df.iloc[:, 1:].values  # ECG data starts from the second column

# Encode labels
train_labels_encoded, train_labels = pd.factorize(train_individuals)
test_labels_encoded, test_labels = pd.factorize(test_individuals)

# Function to detect R-peaks
def detect_r_peaks(ecg_signal, distance=150):
    peaks, _ = scipy.signal.find_peaks(ecg_signal, distance=distance)
    return peaks

# Function to extract PQRS features
def extract_pqrs_features(ecg_signal):
    r_peaks = detect_r_peaks(ecg_signal)
    features = []
    for r_peak in r_peaks:
        p_peak = max(0, r_peak - 20)
        q_peak = max(0, r_peak - 10)
        s_peak = min(len(ecg_signal) - 1, r_peak + 10)
        t_peak = min(len(ecg_signal) - 1, r_peak + 20)

        pqrs_feature = [
            ecg_signal[p_peak] if p_peak < len(ecg_signal) else 0,
            ecg_signal[q_peak] if q_peak < len(ecg_signal) else 0,
            ecg_signal[r_peak] if r_peak < len(ecg_signal) else 0,
            ecg_signal[s_peak] if s_peak < len(ecg_signal) else 0,
            ecg_signal[t_peak] if t_peak < len(ecg_signal) else 0
        ]
        features.append(pqrs_feature)
    return np.array(features)

# Extract PQRS features for training data
train_pqrs_features_list = [extract_pqrs_features(ecg_signal) for ecg_signal in train_ecg_data]
max_length = max(len(seq) for seq in train_pqrs_features_list)
train_pqrs_features_array = pad_sequences(train_pqrs_features_list, maxlen=max_length, padding='post', dtype='float32')

# Normalize PQRS features for training data
scaler = MinMaxScaler()
train_pqrs_features_array = scaler.fit_transform(train_pqrs_features_array.reshape(-1, train_pqrs_features_array.shape[-1]))
train_pqrs_features_array = train_pqrs_features_array.reshape(len(train_pqrs_features_list), max_length, train_pqrs_features_array.shape[-1])

# Extract PQRS features for testing data
test_pqrs_features_list = [extract_pqrs_features(ecg_signal) for ecg_signal in test_ecg_data]
test_pqrs_features_array = pad_sequences(test_pqrs_features_list, maxlen=max_length, padding='post', dtype='float32')

# Normalize PQRS features for testing data
test_pqrs_features_array = scaler.transform(test_pqrs_features_array.reshape(-1, test_pqrs_features_array.shape[-1]))
test_pqrs_features_array = test_pqrs_features_array.reshape(len(test_pqrs_features_list), max_length, test_pqrs_features_array.shape[-1])

# Define the ResNet1D model
def residual_block(x, filters, kernel_size):
    shortcut = x
    x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)
    x = BatchNormalization()(x)
    x = Add()([x, shortcut])
    x = ReLU()(x)
    return x

input_layer = Input(shape=(train_pqrs_features_array.shape[1], train_pqrs_features_array.shape[2]))
x = Conv1D(filters=64, kernel_size=7, padding='same')(input_layer)
x = BatchNormalization()(x)
x = ReLU()(x)

# Add residual blocks
x = residual_block(x, 64, 3)
x = residual_block(x, 64, 3)

x = GlobalAveragePooling1D()(x)
x = Dense(units=64, activation='relu')(x)
x = Dense(units=len(np.unique(train_labels_encoded)), activation='softmax')(x)

model = Model(inputs=input_layer, outputs=x)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Train the ResNet1D model
history = model.fit(train_pqrs_features_array, train_labels_encoded, epochs=1000, batch_size=32, validation_split=0.2)

# Evaluate on test set
test_loss, test_accuracy = model.evaluate(test_pqrs_features_array, test_labels_encoded)
print(f'Test Accuracy: {test_accuracy:.4f}')

# Make predictions
y_pred = np.argmax(model.predict(test_pqrs_features_array), axis=1)

# Generate confusion matrix
cm = confusion_matrix(test_labels_encoded, y_pred)

# Plot confusion matrix with individual names as labels
fig, ax = plt.subplots(figsize=(10, 10))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_labels)
disp.plot(cmap=plt.cm.Blues, ax=ax)
plt.title('Confusion Matrix with Individual Names')
plt.xticks(rotation=45)
plt.show()

# Example prediction function
def classify_ecg(ecg_signal):
    pqrs_features = extract_pqrs_features(ecg_signal)
    if pqrs_features.size == 0:
        raise ValueError("No PQRS features extracted from ECG signal.")

    pqrs_features_array = pad_sequences([pqrs_features], maxlen=max_length, padding='post', dtype='float32')
    pqrs_features_array = scaler.transform(pqrs_features_array.reshape(-1, pqrs_features_array.shape[-1]))
    pqrs_features_array = pqrs_features_array.reshape(1, max_length, pqrs_features_array.shape[-1])
    predictions = model.predict(pqrs_features_array)
    predicted_class = np.argmax(predictions, axis=1)[0]
    return test_labels[predicted_class]

# Example usage
test_ecg_signal = test_pqrs_features_array[0].flatten()  # Replace with your test ECG signal
predicted_label = classify_ecg(test_ecg_signal)
print(f'Predicted individual: {predicted_label}')
